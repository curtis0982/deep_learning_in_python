{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:\n",
    "How is the input supposed to be formatted regarding timesteps (say for instance I want a layer that will have 3 timesteps 1 in the future 1 in the past and 1 current) I see some answers and the API proposing padding and using the embedding layer or to shape the input using a time window (3 in this case) and in any case I can't make heads or tails of the API and SimpleRNN examples are scarce and don't seem to agree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A:\n",
    "Keras SimpleRNN expects an input of size (num_training_examples, num_timesteps, num_features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, suppose I have sequences of counts of numbers of cars driving by an intersection per hour (small example just to illustrate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([[10, 14, 2, 5], [12, 15, 1, 4], [13, 10, 0, 0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: Notice that I was taking observations over four hours, and the last two hours had no cars driving by. That's an example of zero-padding the input, which means making all of the sequences the same length by adding 0s to the end of shorter sequences to match the length of the longest sequence.\n",
    "\n",
    "Keras would expect the following input shape: (X.shape[0], X.shape1, 1), which means I could do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X, (X.shape[0], X.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10],\n",
       "        [14],\n",
       "        [ 2],\n",
       "        [ 5]],\n",
       "\n",
       "       [[12],\n",
       "        [15],\n",
       "        [ 1],\n",
       "        [ 4]],\n",
       "\n",
       "       [[13],\n",
       "        [10],\n",
       "        [ 0],\n",
       "        [ 0]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then I could feed that into the RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=10, activation='relu', input_shape = (X.shape[1], X.shape[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2:\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(output_dim=1, input_shape=(1,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for clarity, my\n",
    "train_x.shape = (73, 84, 400)\n",
    "and\n",
    "vocab_size=400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A:\n",
    "You are not supposed to include n_samples in the input shape of the model. So you have to specify a tuple of size 2 for input shape of a your layer (or set the first element of shape to None). Here Keras automatically adds None to your input shape resulting in ndim=4. More info on this can be found here.\n",
    "\n",
    "Also it appears that your input_dim=400 (assuming you use one-hot coding representation of words in vocabulary) and that your training data consists of 73 texts (pretty small) each having length of 84. So you should probably set input_shape=(84,400)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
